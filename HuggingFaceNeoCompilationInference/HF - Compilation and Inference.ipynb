{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0874d4ab",
   "metadata": {},
   "source": [
    "# Sequence Classfication using HuggingFace DistilBERT Model compiled using Neo on ML_G4DN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ccafaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (4.15.0)\n",
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (2.72.3)\n",
      "Requirement already satisfied: sagemaker_inference in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (1.5.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (2.0.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (4.56.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (1.19.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (0.1.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: protobuf>=3.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (3.17.3)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (0.1.5)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: boto3>=1.20.18 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (1.20.18)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (0.2.8)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (1.2.2)\n",
      "Requirement already satisfied: attrs in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (20.3.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker_inference) (5.8.0)\n",
      "Requirement already satisfied: retrying==1.3.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker_inference) (1.3.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker_inference) (1.6.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sagemaker_inference) (1.15.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.20.18->sagemaker) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.20.18->sagemaker) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.18 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from boto3>=1.20.18->sagemaker) (1.23.18)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.18->boto3>=1.20.18->sagemaker) (1.26.6)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from botocore<1.24.0,>=1.23.18->boto3>=1.20.18->sagemaker) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pandas->sagemaker) (2021.1)\n",
      "Requirement already satisfied: multiprocess>=0.70.12 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker) (0.70.12.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker) (1.6.6.4)\n",
      "Requirement already satisfied: pox>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from pathos->sagemaker) (0.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_latest_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers sagemaker sagemaker_inference --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf19dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c4b57",
   "metadata": {},
   "source": [
    "# 1. Inference without Installing HF transformers in the current Neo GPU inference container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdbfff0",
   "metadata": {},
   "source": [
    "# Tokenization using HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5596fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig,DistilBertForSequenceClassification\n",
    "\n",
    "MODEL = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "model = DistilBertForSequenceClassification.from_pretrained(MODEL, return_dict=False)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "# Setup some example inputs\n",
    "sequence_0 = \"The company HuggingFace is based in New York City\"\n",
    "sequence_1 = \"Apples are especially bad for your health\"\n",
    "sequence_2 = \"HuggingFace's headquarters are situated in Manhattan\"\n",
    "\n",
    "max_length=128\n",
    "paraphrase = tokenizer.encode_plus(sequence_0, sequence_2, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n",
    "not_paraphrase = tokenizer.encode_plus(sequence_0, sequence_1, max_length=max_length, padding='max_length', truncation=True, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aeea900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert example inputs to a format that is compatible with TorchScript tracing\n",
    "example_inputs_paraphrase = paraphrase['input_ids'], paraphrase['attention_mask']\n",
    "example_inputs_not_paraphrase = not_paraphrase['input_ids'], not_paraphrase['attention_mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe678ddb",
   "metadata": {},
   "source": [
    "# Convert HF Model to Neo Compatible Format for compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9d56ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "model_trace = torch.jit.trace(model, example_inputs_paraphrase, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "681a02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trace.save('hf-model-distillbert-traced.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a1c1b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf-model-distillbert-traced.pth\r\n"
     ]
    }
   ],
   "source": [
    "! tar zcvf hf-model-distillbert-traced.tar.gz hf-model-distillbert-traced.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "466b9bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader,s3_path_join\n",
    "\n",
    "# get the s3 bucket\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "# uploads a given file to S3.\n",
    "upload_path = s3_path_join(\"s3://\",sagemaker_session_bucket,\"hf_distillbert_traced\")\n",
    "model_uri = S3Uploader.upload('hf-model-distillbert-traced.tar.gz',upload_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7209eb9",
   "metadata": {},
   "source": [
    "# Compile the HF model  using Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb98b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "import time\n",
    "pytorch_model = PyTorchModel(\n",
    "    model_data=model_uri,\n",
    "    role=role,\n",
    "    entry_point=\"distillbert.py\",\n",
    "    framework_version=\"1.8.1\",\n",
    "    py_version=\"py3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccd78319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "???????????????????????????????.........................................................!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.pytorch.model.PyTorchModel at 0x7f8877621ed0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model.compile(\n",
    "    target_instance_family=\"ml_g4dn\",\n",
    "    input_shape={\"input_ids\": [1, 128], \"attention_mask\": [1, 128]},\n",
    "    compiler_options={\"dtype\": \"int64\"},\n",
    "    output_path=upload_path,\n",
    "    framework=\"pytorch\",\n",
    "    role=role,\n",
    "    job_name=\"distillbert-traced-{}\".format(int(time.time())),\n",
    "    compile_max_run=1500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e8df4",
   "metadata": {},
   "source": [
    "# Host on Sagemaker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f3bebf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.pytorch.model.PyTorchPredictor at 0x7f88761bc390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model.deploy(instance_type=\"ml.g4dn.2xlarge\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c122c",
   "metadata": {},
   "source": [
    "# Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1c611f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sagemaker_inference import encoder, decoder\n",
    "\n",
    "inp = encoder.encode(example_inputs_paraphrase, \"application/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f69d4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import boto3\n",
    "from sagemaker_inference import content_types, encoder, decoder\n",
    "\n",
    "sm_runtime = boto3.Session().client(\"sagemaker-runtime\")\n",
    "request_type = content_types.JSON\n",
    "response_type = content_types.JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f299ee54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[[[-1.8017159700393677, 1.8369837999343872]]]'\n"
     ]
    }
   ],
   "source": [
    "response = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=pytorch_model.endpoint_name, ContentType=request_type, Accept=response_type, Body=inp\n",
    "    )\n",
    "print(response[\"Body\"].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42083324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.616173801931154"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "trial_count = 0\n",
    "num_of_trials = 100\n",
    "while trial_count < num_of_trials:\n",
    "    start_time = time.time()\n",
    "    response = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=pytorch_model.endpoint_name, ContentType=request_type, Accept=response_type, Body=inp\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time = total_time + (end_time - start_time)\n",
    "    trial_count = trial_count + 1\n",
    "    \n",
    "1 / (total_time / 100) # inferences per second    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe43591",
   "metadata": {},
   "source": [
    "# 2. Install HF transformers in the GPU inference container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "969b138a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-086613482928/hf_distillbert_traced/hf-model-distillbert-traced-ml_g4dn.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Add requirements.txt with huggingface transformers in the compiled model artifact\n",
    "# This will install HF transformers on container startup\n",
    "\n",
    "print(pytorch_model.model_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43691b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-086613482928/hf_distillbert_traced/hf-model-distillbert-traced-ml_g4dn.tar.gz to ./hf-model-distillbert-traced-ml_g4dn.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Change S3 URI below\n",
    "! aws s3 cp s3://sagemaker-us-west-2-086613482928/hf_distillbert_traced/hf-model-distillbert-traced-ml_g4dn.tar.gz  ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ded4298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_input.pkl\n",
      "10951053_0_Neo.meta\n",
      "compiled.pt\n",
      "10951053_0_Neo.so\n",
      "10951053_0_Neo.json\n",
      "dlr.h\n",
      "libdlr.so\n",
      "10951053_0_Neo.params\n",
      "IOC-INF/\n",
      "IOC-INF/metadata.json\n",
      "manifest\n"
     ]
    }
   ],
   "source": [
    "! rm -rf distillbert_compiled\n",
    "! mkdir -p distillbert_compiled\n",
    "! tar -xzvf hf-model-distillbert-traced-ml_g4dn.tar.gz -C distillbert_compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbdc46e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p distillbert_compiled/code\n",
    "! cp requirements.txt distillbert_compiled/code/\n",
    "! cp distillbertreq.py distillbert_compiled/code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1710eb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10951053_0_Neo.json\n",
      "10951053_0_Neo.meta\n",
      "10951053_0_Neo.params\n",
      "10951053_0_Neo.so\n",
      "code/\n",
      "code/requirements.txt\n",
      "code/distillbertreq.py\n",
      "compiled.pt\n",
      "dlr.h\n",
      "IOC-INF/\n",
      "IOC-INF/metadata.json\n",
      "libdlr.so\n",
      "manifest\n",
      "sample_input.pkl\n"
     ]
    }
   ],
   "source": [
    "! cd distillbert_compiled ; tar -czvf hf-model-distillbert-traced-ml_g4dn-req.tar.gz * ; mv hf-model-distillbert-traced-ml_g4dn-req.tar.gz ../\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7cfb3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri_req = S3Uploader.upload('hf-model-distillbert-traced-ml_g4dn-req.tar.gz',upload_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef405784",
   "metadata": {},
   "source": [
    "# Deploy on Sagemaker¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17eb1b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model_req = PyTorchModel(\n",
    "    model_data=model_uri_req,\n",
    "    role=role,\n",
    "    entry_point=\"distillbertreq.py\",\n",
    "    framework_version=\"1.8.1\",\n",
    "    py_version=\"py3\",\n",
    "    image_uri=\"301217895009.dkr.ecr.us-west-2.amazonaws.com/sagemaker-inference-pytorch:1.8.1-gpu-py3\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b08734f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sagemaker.pytorch.model.PyTorchPredictor at 0x7f8875d5f3d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_model_req.deploy(instance_type=\"ml.g4dn.2xlarge\", initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da95f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapos = {\n",
    "\"inputs\": [\"The company HuggingFace is based in New York City\", \"HuggingFace's headquarters are situated in Manhattan\"]\n",
    "}\n",
    "dataneg = {\n",
    "\"inputs\": [\"The company HuggingFace is based in New York City\", \"Apples are especially bad for your health\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddcc85b",
   "metadata": {},
   "source": [
    "# Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fc85708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[{\"label\": \"POSITIVE\", \"score\": 0.9743868112564087}]'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Infer \"a sentence\"\n",
    "\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=pytorch_model_req.endpoint_name, ContentType=request_type, Accept=response_type, Body=json.dumps(datapos)\n",
    "    )\n",
    "response[\"Body\"].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5e3de7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'[{\"label\": \"NEGATIVE\", \"score\": 0.9997486472129822}]'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Infer \"not a sentence\"\n",
    "response = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=pytorch_model_req.endpoint_name, ContentType=request_type, Accept=response_type, Body=json.dumps(dataneg)\n",
    "    )\n",
    "response[\"Body\"].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6df9ce6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.803152878660576"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_time = 0\n",
    "trial_count = 0\n",
    "num_of_trials = 100\n",
    "\n",
    "\n",
    "while trial_count < num_of_trials:\n",
    "    start_time = time.time()\n",
    "    response = sm_runtime.invoke_endpoint(\n",
    "        EndpointName=pytorch_model_req.endpoint_name, ContentType=request_type, Accept=response_type, Body=json.dumps(datapos)\n",
    "    )\n",
    "    end_time = time.time()\n",
    "\n",
    "    total_time = total_time + (end_time - start_time)\n",
    "    trial_count = trial_count + 1\n",
    "    \n",
    "1 / (total_time / 100) # inferences per second    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45385135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p37",
   "language": "python",
   "name": "conda_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
